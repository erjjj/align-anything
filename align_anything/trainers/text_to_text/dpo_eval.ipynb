{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8d8ceb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin01/anaconda3/envs/align-anything/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-02 02:18:08,332] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin01/anaconda3/envs/align-anything/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/admin01/anaconda3/envs/align-anything/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/admin01/anaconda3/envs/align-anything/lib/libcufile.so: undefined reference to `dlvsym'\n",
      "/home/admin01/anaconda3/envs/align-anything/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/admin01/anaconda3/envs/align-anything/lib/libcufile.so: undefined reference to `dlopen'\n",
      "/home/admin01/anaconda3/envs/align-anything/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/admin01/anaconda3/envs/align-anything/lib/libcufile.so: undefined reference to `dlclose'\n",
      "/home/admin01/anaconda3/envs/align-anything/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/admin01/anaconda3/envs/align-anything/lib/libcufile.so: undefined reference to `dlerror'\n",
      "/home/admin01/anaconda3/envs/align-anything/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/admin01/anaconda3/envs/align-anything/lib/libcufile.so: undefined reference to `dlsym'\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from align_anything.datasets.text_to_text.preference import PreferenceBatch, PreferenceDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from align_anything.configs.template import ChatTemplate\n",
    "from align_anything.models.pretrained_model import load_pretrained_models\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0916034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_from_model(model,tokenizer,prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "    # generated_ids:Tensor其中包含输入数据，可以直接被用于reward_model打分，这一部分通过下面验证，\n",
    "    # 可以发现用于训练reward_model的input_ids数据和generated_ids是一个结构的\n",
    "    # 因为它们decode后都是包含前置system、输入user、回答response三个部分\n",
    "    generated_ids = model.generate(\n",
    "        model_inputs.input_ids,\n",
    "        max_new_tokens=512\n",
    "    )\n",
    "    # generated_ids = [\n",
    "    #     output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    # ]\n",
    "    # 把回答全部输出出来，更美观\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return generated_ids,response\n",
    "\n",
    "def get_rewards_from_two_model(model1,tokenizer1,model2,tokenizer2,prompt,model_reward):\n",
    "    generated_ids_1,response_1=get_response_from_model(model1,tokenizer1,prompt)\n",
    "    generated_ids_2,response_2=get_response_from_model(model2,tokenizer2,prompt)\n",
    "    output_1=model_reward(**{'input_ids':generated_ids_1})\n",
    "    output_2=model_reward(**{'input_ids':generated_ids_2})\n",
    "    return response_1,response_2,output_1.end_scores,output_2.end_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ca165a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Sliding Window Attention is enabled but not implemented for `eager`; unexpected results may be encountered.\n",
      "/home/admin01/Shizexi/align-anything/align_anything/models/pretrained_model.py:309: RuntimeWarning: The tokenizer vocabulary size (151665) is different from the model embedding size (151936) before resizing.\n",
      "  resize_tokenizer_embedding(tokenizer=tokenizer, model=model)\n",
      "/home/admin01/Shizexi/align-anything/align_anything/models/pretrained_model.py:309: RuntimeWarning: The tokenizer vocabulary size (151665) is different from the model embedding size (151936) after resizing.\n",
      "  resize_tokenizer_embedding(tokenizer=tokenizer, model=model)\n"
     ]
    }
   ],
   "source": [
    "# 原始模型提取\n",
    "model_raw = AutoModelForCausalLM.from_pretrained(\n",
    "    \"../../../scripts/qwen2_5/Qwen2.5-0.5B-Instruct\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer_raw = AutoTokenizer.from_pretrained(\"../../../scripts/qwen2_5/Qwen2.5-0.5B-Instruct\")\n",
    "\n",
    "# dpo强化学习训练后的模型提取\n",
    "model_dpo = AutoModelForCausalLM.from_pretrained(\n",
    "    \"../../../scripts/outputs/qwen_2_5_dpo/slice_end\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer_dpo = AutoTokenizer.from_pretrained(\"../../../scripts/outputs/qwen_2_5_dpo/slice_end\")\n",
    "\n",
    "# 加载奖励模型model_reward\n",
    "model_reward, tokenizer_reward, processor_reward = load_pretrained_models(\n",
    "    '../../../scripts/outputs/qwen_2_5_rm/slice_end',\n",
    "    model_max_length=512,\n",
    "    padding_side='right',\n",
    "    trust_remote_code=True,\n",
    "    is_reward_model=True,\n",
    "    processor_kwargs=None,\n",
    "    auto_device_mapping=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c22a1fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.203125\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Give me a short introduction to large language model.\n",
      "assistant\n",
      "A large language model (LLM) is a type of artificial intelligence that can generate human-like text based on the input provided by a user or an AI system. These models are designed to understand and respond to complex questions, provide accurate information, and perform various tasks such as translation, summarization, and question answering. They are typically trained using large amounts of data, which enables them to learn from many examples and improve their performance over time. LLMs have become increasingly important in fields such as natural language processing, machine learning, and computer vision, where they are used for a wide range of applications, including automated translations, document generation, and speech synthesis.\n",
      "-1.765625\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Give me a short introduction to large language model.\n",
      "assistant\n",
      "A large language model, also known as a machine learning model, is a type of artificial intelligence (AI) that can generate human-like text. These models are designed to mimic the complexity and flexibility of human language, making them capable of understanding and generating text in a wide range of topics and styles. They are commonly used in various applications, such as chatbots, virtual assistants, and language translation systems. Large language models are trained on large amounts of text data, which allows them to learn patterns and relationships in language, and use this knowledge to generate coherent and contextually appropriate responses.\n"
     ]
    }
   ],
   "source": [
    "# 这是根据特定的prompt生成的回复\n",
    "response_raw,response_dpo,reward_raw,reward_dpo=get_rewards_from_two_model(model_raw,tokenizer_raw,model_dpo,tokenizer_dpo,prompt,model_reward)\n",
    "print(reward_raw[0].item())\n",
    "print(response_raw)\n",
    "print(reward_dpo[0].item())\n",
    "print(response_dpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90a24f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"../../../assets/text_to_text/hw/val.json\", lines=True)  \n",
    "data_batch=[]\n",
    "for idx, question in enumerate(df['question']):\n",
    "    data_batch.append(question)\n",
    "    if idx>=5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2627fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 下面应该根据特定的eval数据集批量生成回复并计算reward\n",
    "def get_batch_rewards_from_two_model(model1,tokenizer1,model2,tokenizer2,data_batch,model_reward,output_file='version1.json'):\n",
    "    results=[]\n",
    "    for prompt in tqdm(data_batch, desc=\"Evaluating prompts\"):\n",
    "        response_raw,response_dpo,reward_raw,reward_dpo=\\\n",
    "            get_rewards_from_two_model(model1,tokenizer1,model2,tokenizer2,prompt,model_reward)\n",
    "        result = {\n",
    "            \"prompt\": prompt,\n",
    "            \"response_raw\": response_raw,\n",
    "            \"response_dpo\": response_dpo,\n",
    "            \"reward_raw\": reward_raw[0].item(),\n",
    "            \"reward_dpo\": reward_dpo[0].item()\n",
    "        }\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "    # 写入 JSON 文件\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"已保存结果到 {output_file}\")\n",
    "    return results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffe815e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating prompts: 100%|██████████| 3/3 [00:53<00:00, 17.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存结果到 version1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res=get_batch_rewards_from_two_model(model_raw,tokenizer_raw,model_dpo,tokenizer_dpo,data_batch[:3],model_reward,output_file='version1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60984ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 30430 examples [00:00, 33753.81 examples/s]\n",
      "Generating validation split: 1000 examples [00:00, 37582.70 examples/s]\n",
      "Filtering valid indices: 100%|██████████| 30430/30430 [00:06<00:00, 4436.11it/s]\n",
      "Filtering valid indices: 100%|██████████| 1000/1000 [00:00<00:00, 5698.76it/s]\n"
     ]
    }
   ],
   "source": [
    "infer_batch = lambda batch: {k: v.to(device) for k, v in batch.items() if k != 'meta_info'}\n",
    "formatter=tokenizer_dpo\n",
    "custom_formatter = (\n",
    "    model_dpo.apply_chat_template\n",
    "    if hasattr(model_dpo, 'apply_chat_template')\n",
    "    else None\n",
    ")\n",
    "train_template = ChatTemplate(\n",
    "    formatter, 'HOMEWORK', custom_formatter\n",
    ")\n",
    "train_dataset = PreferenceDataset(\n",
    "    path='../../../assets/text_to_text/hw',\n",
    "    template=train_template,\n",
    "    tokenizer=tokenizer_dpo,\n",
    "    split='train',\n",
    ")\n",
    "\n",
    "eval_dataset = PreferenceDataset(\n",
    "    path='../../../assets/text_to_text/hw',\n",
    "    template=train_template,\n",
    "    tokenizer=tokenizer_dpo,\n",
    "    split='validation',\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    collate_fn=train_dataset.get_collator(),\n",
    "    #sampler=DistributedSampler(train_dataset, shuffle=True),\n",
    "    batch_size=1,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    collate_fn=train_dataset.get_collator(),\n",
    "    #sampler=DistributedSampler(train_dataset, shuffle=True),\n",
    "    batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feac4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin01/Shizexi/align-anything/align_anything/models/pretrained_model.py:309: RuntimeWarning: The tokenizer vocabulary size (151665) is different from the model embedding size (151936) before resizing.\n",
      "  resize_tokenizer_embedding(tokenizer=tokenizer, model=model)\n",
      "/home/admin01/Shizexi/align-anything/align_anything/models/pretrained_model.py:309: RuntimeWarning: The tokenizer vocabulary size (151665) is different from the model embedding size (151936) after resizing.\n",
      "  resize_tokenizer_embedding(tokenizer=tokenizer, model=model)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bab38e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1172]], device='cuda:0', grad_fn=<ToCopyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model_reward(**{'input_ids':test_ids}).end_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11007fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.\\nuser\\nCan a Muslim person use pork flavoring?\\nassistant\\nNo, a Muslim person cannot use pork flavoring as it is haram (prohibited) for them according to their religion. Pork is forbidden in the Quran and any ingredient containing pork flavoring is also off limits. It is important for Muslims to abstain from all types of haram food and drink, such as alcohol and other non-halal meats. Pork flavoring should not be used by Muslims since it will lead them away from their faith.\\n', 'system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.\\nuser\\nCan a Muslim person use pork flavoring?\\nassistant\\nNo, a Muslim person cannot use pork flavoring as it is forbidden in Islam. Muslims consider pork to be impure and forbidden, and thus, consuming it or using it in any way is not allowed. Furthermore, touching or consuming any pork products is also forbidden for Muslims.\\n']\n",
      "batch {'meta_info': {'response_lens': [92, 56]}, 'input_ids': tensor([[151644,   8948,    198,   2610,    525,   1207,  16948,     11,   3465,\n",
      "            553,  54364,  14817,     13,   1446,    525,    264,  10950,  17847,\n",
      "             13, 151645,    198, 151644,    872,    198,   6713,    264,  10240,\n",
      "           1697,    990,  35067,  17172,    287,     30, 151645,    198, 151644,\n",
      "          77091,    198,   2753,     11,    264,  10240,   1697,   4157,    990,\n",
      "          35067,  17172,    287,    438,    432,    374,    305,    637,    320,\n",
      "            776,  92517,      8,    369,   1105,   4092,    311,    862,  13587,\n",
      "             13,  83934,    374,  36813,    304,    279,  65660,    323,    894,\n",
      "          24763,   8482,  35067,  17172,    287,    374,   1083,   1007,  13388,\n",
      "             13,   1084,    374,   2989,    369,  19503,    311,  62844,    466,\n",
      "            504,    678,   4494,    315,    305,    637,   3607,    323,   7027,\n",
      "             11,   1741,    438,  12904,    323,   1008,   2477,   2832,    278,\n",
      "            278,  62775,     13,  83934,  17172,    287,   1265,    537,    387,\n",
      "           1483,    553,  19503,   2474,    432,    686,   2990,   1105,   3123,\n",
      "            504,    862,   9881,     13, 151645,    198],\n",
      "        [151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151644,   8948,    198,   2610,    525,   1207,  16948,     11,   3465,\n",
      "            553,  54364,  14817,     13,   1446,    525,    264,  10950,  17847,\n",
      "             13, 151645,    198, 151644,    872,    198,   6713,    264,  10240,\n",
      "           1697,    990,  35067,  17172,    287,     30, 151645,    198, 151644,\n",
      "          77091,    198,   2753,     11,    264,  10240,   1697,   4157,    990,\n",
      "          35067,  17172,    287,    438,    432,    374,  36813,    304,  14910,\n",
      "             13,  19503,   2908,  35067,    311,    387,   3163,    552,    323,\n",
      "          36813,     11,    323,   8450,     11,  34108,    432,    476,   1667,\n",
      "            432,    304,    894,   1616,    374,    537,   5420,     13,  23405,\n",
      "             11,  30587,    476,  34108,    894,  35067,   3871,    374,   1083,\n",
      "          36813,    369,  19503,     13, 151645,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
      "output tensor([[2.1094],\n",
      "        [0.5859]], device='cuda:0', grad_fn=<ToCopyBackward0>)\n",
      "meta_info\n",
      "input_ids\n",
      "attention_mask\n"
     ]
    }
   ],
   "source": [
    "rewards=[]\n",
    "num_correct_predictions=0\n",
    "num_total_predictions=0\n",
    "for batch in eval_dataloader:\n",
    "    output = model_reward(**infer_batch(batch))\n",
    "    \n",
    "    response = tokenizer_reward.batch_decode(batch['input_ids'], skip_special_tokens=True)\n",
    "    print(response)\n",
    "    print('batch',batch)\n",
    "    print('output',output.end_scores)\n",
    "    for i,j in batch.items():\n",
    "        print(i)\n",
    "    break\n",
    "    # end_scores = output.end_scores\n",
    "    # higher_end_rewards, lower_end_rewards = end_scores.squeeze(dim=-1).chunk(\n",
    "    #     chunks=2, dim=0\n",
    "    # )\n",
    "    # batch_size = higher_end_rewards.size(0)\n",
    "    # num_correct_predictions += (higher_end_rewards > lower_end_rewards).sum()\n",
    "    # num_total_predictions += batch_size\n",
    "\n",
    "    # rewards.extend([higher_end_rewards, lower_end_rewards])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fcbb4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbd52a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'meta_info': {'response_lens': [258, 258, 156, 43, 94, 94, 57, 68, 51, 41, 82, 212, 32, 46, 125, 88, 19, 275, 75, 14, 237, 45, 41, 18, 27, 73, 10, 144, 27, 21, 50, 71]}, 'input_ids': tensor([[151644,   8948,    198,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,      0, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [59, 349, 63, 49, 70, 55, 54, 70, 43, 41, 91, 82, 219, 134, 109, 99, 32, 167, 68, 33, 79, 16, 105, 97, 49, 17, 39, 87, 239, 102, 114, 76]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151644,   8948,    198,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,      0, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [97, 96, 144, 81, 116, 85, 414, 102, 107, 85, 84, 187, 323, 115, 52, 92, 39, 48, 157, 25, 119, 130, 272, 55, 73, 219, 37, 85, 48, 100, 13, 39]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,  10851, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [47, 57, 139, 33, 85, 188, 98, 42, 389, 52, 114, 124, 23, 538, 107, 79, 131, 25, 60, 42, 118, 87, 107, 24, 485, 109, 127, 101, 44, 623, 136, 39]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151644,   8948,    198,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [712, 37, 12, 156, 48, 292, 131, 63, 105, 107, 297, 135, 635, 93, 84, 80, 287, 26, 59, 64, 51, 81, 126, 154, 107, 90, 126, 113, 712, 90, 88, 90]}, 'input_ids': tensor([[151644,   8948,    198,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,      8, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [41, 100, 112, 78, 43, 99, 141, 336, 59, 71, 78, 22, 80, 206, 610, 11, 31, 118, 112, 61, 55, 48, 124, 354, 11, 58, 118, 43, 70, 116, 51, 26]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [27, 45, 67, 145, 120, 108, 108, 44, 105, 185, 63, 75, 150, 159, 116, 78, 27, 73, 41, 100, 64, 129, 113, 27, 9, 56, 40, 58, 45, 76, 30, 32]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [74, 27, 88, 141, 57, 79, 59, 83, 93, 64, 825, 124, 35, 78, 16, 497, 60, 23, 53, 64, 80, 38, 104, 154, 28, 26, 372, 58, 27, 10, 25, 835]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,   1189, 151645,    198],\n",
      "        [151644,   8948,    198,  ...,     25, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [42, 118, 9, 84, 71, 577, 65, 134, 156, 22, 60, 33, 60, 128, 70, 107, 19, 116, 9, 50, 55, 361, 33, 57, 112, 77, 26, 26, 43, 85, 54, 67]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,   3263, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,      0, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [11, 79, 87, 44, 141, 65, 54, 49, 38, 50, 28, 121, 124, 24, 73, 95, 18, 53, 119, 36, 12, 41, 56, 125, 45, 29, 56, 69, 135, 23, 17, 39]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     30, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [161, 370, 240, 71, 136, 51, 88, 22, 100, 156, 171, 33, 128, 65, 336, 98, 78, 50, 166, 113, 96, 18, 50, 47, 38, 67, 182, 42, 85, 75, 338, 46]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151644,   8948,    198,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [466, 35, 214, 25, 107, 645, 55, 75, 102, 65, 284, 75, 42, 91, 66, 7, 326, 7, 169, 75, 48, 436, 74, 57, 69, 129, 106, 116, 34, 31, 100, 8]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,   3263, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,   3720, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [97, 49, 148, 106, 74, 138, 70, 31, 93, 65, 96, 27, 15, 667, 78, 83, 101, 59, 39, 77, 44, 65, 83, 68, 51, 1, 31, 97, 12, 778, 56, 95]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,   4427, 151645,    198],\n",
      "        ...,\n",
      "        [151644,   8948,    198,  ...,  33702, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [52, 54, 77, 61, 78, 34, 54, 75, 85, 110, 154, 37, 351, 180, 78, 79, 13, 53, 53, 57, 71, 7, 145, 77, 88, 106, 86, 29, 601, 130, 117, 95]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,      0, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [92, 18, 65, 74, 75, 31, 78, 59, 81, 58, 177, 252, 71, 90, 18, 81, 108, 40, 152, 45, 55, 105, 66, 70, 26, 56, 36, 101, 85, 67, 67, 81]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     30, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [93, 60, 84, 71, 704, 89, 44, 8, 49, 51, 211, 323, 53, 70, 10, 127, 108, 64, 99, 128, 241, 60, 54, 9, 132, 33, 141, 464, 32, 44, 62, 84]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [181, 65, 32, 108, 63, 26, 144, 88, 502, 22, 78, 113, 12, 13, 233, 323, 28, 101, 32, 232, 10, 10, 125, 125, 354, 8, 48, 120, 10, 40, 177, 272]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,    760, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,      0, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     60, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [77, 60, 271, 102, 30, 109, 98, 136, 39, 105, 29, 313, 176, 71, 117, 92, 118, 37, 149, 47, 122, 161, 77, 62, 40, 214, 58, 105, 179, 69, 108, 95]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [82, 336, 33, 102, 90, 34, 12, 24, 75, 42, 66, 105, 15, 74, 518, 62, 3, 809, 47, 56, 95, 50, 11, 17, 87, 36, 30, 26, 74, 40, 264, 28]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [72, 46, 46, 15, 67, 10, 99, 69, 91, 253, 22, 24, 94, 53, 156, 134, 44, 25, 20, 17, 36, 16, 60, 31, 67, 227, 46, 15, 64, 61, 269, 82]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151644,   8948,    198,  ...,    368, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [63, 84, 4, 169, 27, 179, 47, 319, 81, 518, 31, 87, 111, 77, 111, 54, 46, 60, 14, 119, 24, 65, 69, 180, 107, 368, 15, 218, 50, 31, 57, 77]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,   1189, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [89, 27, 23, 88, 104, 300, 56, 14, 65, 54, 96, 24, 88, 13, 101, 30, 62, 47, 37, 104, 58, 228, 58, 70, 33, 19, 140, 31, 87, 5, 62, 62]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [215, 58, 582, 91, 127, 121, 72, 385, 72, 186, 22, 36, 20, 141, 82, 223, 93, 48, 499, 186, 53, 113, 66, 223, 32, 34, 7, 103, 82, 141, 27, 190]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151644,   8948,    198,  ...,   8660, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,   1899, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [87, 11, 68, 18, 180, 79, 14, 69, 127, 57, 142, 59, 138, 49, 149, 95, 31, 43, 79, 12, 88, 82, 43, 23, 71, 35, 159, 63, 100, 48, 75, 210]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,   1987, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [102, 11, 166, 1, 8, 140, 80, 55, 82, 51, 67, 104, 12, 125, 51, 330, 54, 8, 46, 159, 11, 64, 105, 90, 16, 24, 148, 273, 40, 129, 89, 227]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     30, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,      0, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [54, 10, 14, 68, 168, 84, 107, 70, 78, 62, 255, 790, 39, 50, 86, 783, 39, 35, 13, 42, 88, 140, 100, 119, 29, 49, 57, 575, 91, 32, 143, 836]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151644,   8948,    198,  ...,     11, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [83, 32, 47, 10, 25, 139, 282, 53, 67, 32, 71, 28, 357, 118, 50, 103, 105, 109, 148, 55, 17, 93, 57, 28, 43, 128, 64, 76, 177, 374, 47, 56]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151644,   8948,    198,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [609, 100, 205, 71, 90, 20, 72, 29, 45, 62, 62, 146, 46, 78, 63, 83, 242, 52, 71, 24, 39, 51, 32, 18, 44, 114, 43, 117, 103, 67, 97, 25]}, 'input_ids': tensor([[151644,   8948,    198,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,      0, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [46, 407, 45, 113, 51, 103, 91, 49, 7, 554, 64, 19, 102, 60, 48, 63, 41, 314, 31, 84, 32, 68, 104, 131, 5, 453, 151, 17, 96, 50, 52, 125]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [102, 65, 46, 105, 210, 156, 99, 542, 65, 26, 122, 22, 73, 58, 71, 41, 77, 188, 38, 53, 27, 91, 59, 226, 39, 12, 60, 9, 64, 90, 66, 58]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,    322, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     40, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [50, 72, 80, 76, 122, 134, 138, 455, 19, 41, 126, 18, 19, 108, 154, 81, 25, 56, 87, 48, 139, 147, 84, 280, 22, 64, 57, 57, 13, 40, 63, 44]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [131, 80, 1, 66, 93, 29, 108, 110, 48, 89, 22, 74, 78, 137, 79, 115, 26, 138, 2, 19, 58, 15, 66, 26, 82, 84, 22, 58, 58, 101, 98, 23]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151644,   8948,  ...,   2753, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     30, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [247, 125, 140, 102, 14, 78, 77, 58, 456, 52, 108, 32, 50, 42, 51, 17, 272, 33, 77, 39, 11, 97, 25, 37, 387, 73, 65, 122, 72, 18, 118, 28]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [35, 34, 10, 85, 24, 77, 25, 231, 39, 107, 60, 116, 54, 64, 44, 50, 73, 49, 143, 135, 78, 116, 39, 8, 44, 82, 56, 142, 60, 20, 40, 65]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,   1783, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [71, 45, 80, 79, 84, 92, 115, 91, 98, 88, 133, 75, 42, 148, 31, 111, 79, 53, 38, 68, 80, 59, 75, 52, 54, 97, 58, 49, 20, 76, 33, 112]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,   1189, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,      0, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [118, 70, 17, 118, 72, 71, 70, 54, 10, 91, 30, 107, 329, 95, 90, 64, 124, 24, 37, 95, 129, 56, 54, 42, 9, 54, 25, 158, 269, 23, 20, 52]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [81, 80, 33, 32, 152, 88, 8, 50, 84, 85, 79, 94, 84, 42, 40, 56, 86, 39, 31, 28, 147, 111, 17, 62, 168, 162, 214, 30, 37, 15, 46, 137]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [86, 528, 54, 107, 73, 81, 82, 248, 17, 60, 17, 59, 80, 106, 53, 221, 70, 266, 18, 173, 85, 58, 88, 567, 18, 104, 6, 38, 65, 95, 52, 78]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [34, 16, 145, 30, 49, 64, 13, 273, 62, 10, 26, 29, 90, 115, 93, 113, 26, 46, 120, 17, 46, 102, 61, 188, 46, 31, 2, 26, 69, 104, 14, 74]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     30, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [34, 116, 59, 54, 94, 30, 81, 24, 59, 51, 61, 80, 107, 108, 57, 38, 16, 112, 56, 43, 78, 49, 70, 16, 50, 47, 68, 29, 140, 46, 52, 128]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,   8958, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,      4, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [197, 559, 102, 59, 17, 80, 705, 117, 139, 32, 56, 72, 69, 134, 150, 64, 71, 220, 73, 10, 6, 92, 596, 107, 112, 31, 143, 77, 31, 77, 184, 53]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,      0, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [121, 115, 70, 77, 50, 52, 39, 30, 121, 38, 150, 161, 12, 53, 115, 24, 13, 96, 28, 58, 82, 118, 27, 32, 79, 10, 126, 89, 15, 29, 104, 63]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [26, 41, 348, 75, 169, 94, 71, 190, 196, 61, 33, 87, 518, 154, 31, 85, 7, 11, 81, 61, 16, 103, 49, 109, 50, 68, 8, 87, 484, 83, 87, 148]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [513, 108, 44, 107, 207, 85, 21, 89, 71, 31, 107, 70, 447, 240, 96, 52, 266, 59, 45, 105, 71, 40, 10, 82, 52, 36, 161, 45, 384, 88, 79, 167]}, 'input_ids': tensor([[151644,   8948,    198,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [72, 208, 31, 166, 67, 122, 40, 44, 97, 27, 94, 147, 65, 24, 68, 52, 44, 105, 16, 93, 34, 50, 40, 20, 31, 129, 41, 27, 123, 1, 1, 76]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     76, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,  89500, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,  23362, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [31, 79, 177, 61, 80, 114, 335, 160, 82, 116, 97, 345, 92, 13, 61, 81, 13, 121, 55, 27, 16, 86, 185, 201, 91, 121, 105, 218, 62, 10, 90, 103]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,      4, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [480, 40, 159, 41, 8, 118, 74, 136, 107, 27, 137, 82, 35, 125, 70, 145, 338, 68, 112, 52, 5, 46, 72, 113, 87, 24, 92, 55, 82, 137, 101, 211]}, 'input_ids': tensor([[151644,   8948,    198,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,      0, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [17, 23, 46, 79, 151, 222, 26, 102, 53, 107, 100, 141, 63, 221, 600, 415, 62, 31, 62, 78, 70, 36, 21, 113, 17, 103, 120, 82, 91, 140, 603, 52]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,      0, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,      0, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [108, 382, 318, 41, 12, 492, 64, 49, 7, 95, 352, 93, 44, 146, 95, 80, 54, 111, 54, 97, 9, 296, 35, 17, 3, 49, 204, 147, 28, 118, 55, 66]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [18, 39, 130, 27, 123, 110, 96, 85, 89, 221, 102, 84, 83, 66, 53, 29, 49, 53, 57, 35, 84, 66, 75, 74, 58, 38, 75, 75, 140, 43, 27, 66]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [46, 10, 73, 48, 19, 17, 193, 21, 31, 67, 32, 62, 13, 91, 84, 90, 94, 48, 131, 165, 132, 14, 53, 92, 22, 98, 33, 132, 17, 84, 65, 151]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [99, 52, 79, 47, 64, 134, 68, 216, 15, 61, 78, 83, 108, 50, 49, 287, 73, 48, 86, 33, 133, 124, 317, 89, 1, 109, 64, 40, 74, 29, 54, 55]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [61, 70, 43, 7, 208, 79, 23, 76, 111, 89, 106, 15, 108, 47, 260, 37, 101, 62, 42, 7, 230, 42, 22, 40, 100, 17, 136, 9, 35, 41, 130, 31]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [396, 123, 19, 58, 12, 183, 40, 41, 53, 82, 20, 65, 86, 85, 55, 108, 393, 45, 47, 92, 136, 75, 66, 41, 23, 61, 21, 98, 67, 34, 99, 77]}, 'input_ids': tensor([[151644,   8948,    198,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [59, 110, 184, 53, 13, 47, 74, 64, 104, 769, 10, 10, 49, 91, 65, 24, 108, 110, 107, 18, 65, 108, 59, 129, 118, 421, 24, 77, 60, 77, 80, 64]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [48, 41, 98, 67, 321, 51, 136, 98, 52, 125, 106, 46, 105, 320, 72, 25, 53, 69, 92, 114, 523, 63, 126, 128, 118, 85, 10, 53, 28, 471, 133, 101]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [94, 673, 66, 90, 104, 74, 108, 89, 66, 109, 60, 57, 117, 101, 122, 317, 84, 646, 523, 30, 49, 79, 112, 375, 143, 68, 97, 66, 91, 120, 45, 485]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151644,   8948,    198,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     30, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,      0, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [51, 175, 168, 43, 153, 61, 119, 134, 64, 90, 71, 66, 111, 696, 28, 161, 36, 104, 20, 18, 121, 85, 131, 128, 37, 62, 63, 55, 45, 803, 14, 61]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151644,   8948,    198,  ...,    645, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [89, 84, 71, 578, 109, 273, 115, 77, 13, 97, 115, 749, 59, 27, 15, 62, 53, 52, 59, 583, 3, 108, 67, 83, 8, 83, 128, 146, 18, 11, 35, 54]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,   3263, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [111, 5, 90, 138, 96, 63, 221, 113, 33, 28, 26, 116, 109, 35, 118, 419, 122, 9, 93, 118, 46, 55, 80, 51, 14, 45, 169, 70, 89, 12, 77, 44]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,   1341, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [86, 29, 25, 50, 2, 39, 74, 8, 51, 40, 14, 142, 552, 23, 64, 16, 82, 22, 60, 49, 32, 34, 63, 117, 136, 103, 13, 71, 14, 34, 65, 103]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,  11204, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [77, 108, 78, 131, 84, 44, 101, 448, 119, 391, 40, 40, 48, 108, 19, 18, 109, 131, 72, 51, 64, 65, 34, 78, 74, 344, 61, 20, 66, 130, 69, 41]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n",
      "{'meta_info': {'response_lens': [47, 71, 70, 49, 82, 26, 64, 40, 72, 91, 105, 55, 100, 44]}, 'input_ids': tensor([[151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        ...,\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198],\n",
      "        [151643, 151643, 151643,  ...,     13, 151645,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "for idx ,batch, in enumerate(train_dataloader):\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ea1303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = []\n",
    "\n",
    "with open('../../../assets/text_to_text/hw/val.json', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:  # 跳过空行\n",
    "            obj = json.loads(line)\n",
    "            data.append(obj['question'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e86c04c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating prompts:   0%|          | 2/1000 [00:46<6:25:29, 23.18s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m res=\u001b[43mget_batch_rewards_from_two_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtokenizer_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_dpo\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtokenizer_dpo\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_reward\u001b[49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmam.json\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mget_batch_rewards_from_two_model\u001b[39m\u001b[34m(model1, tokenizer1, model2, tokenizer2, data_batch, model_reward, output_file)\u001b[39m\n\u001b[32m      3\u001b[39m results=[]\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m tqdm(data_batch, desc=\u001b[33m\"\u001b[39m\u001b[33mEvaluating prompts\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      5\u001b[39m     response_raw,response_dpo,reward_raw,reward_dpo=\\\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m         \u001b[43mget_rewards_from_two_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtokenizer1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtokenizer2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_reward\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     result = {\n\u001b[32m      8\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: prompt,\n\u001b[32m      9\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mresponse_raw\u001b[39m\u001b[33m\"\u001b[39m: response_raw,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mreward_dpo\u001b[39m\u001b[33m\"\u001b[39m: reward_dpo\n\u001b[32m     13\u001b[39m     }\n\u001b[32m     15\u001b[39m     results.append(result)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mget_rewards_from_two_model\u001b[39m\u001b[34m(model1, tokenizer1, model2, tokenizer2, prompt, model_reward)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_rewards_from_two_model\u001b[39m(model1,tokenizer1,model2,tokenizer2,prompt,model_reward):\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     generated_ids_1,response_1=\u001b[43mget_response_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtokenizer1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     generated_ids_2,response_2=get_response_from_model(model2,tokenizer2,prompt)\n\u001b[32m     29\u001b[39m     output_1=model_reward(**{\u001b[33m'\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m'\u001b[39m:generated_ids_1})\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mget_response_from_model\u001b[39m\u001b[34m(model, tokenizer, prompt)\u001b[39m\n\u001b[32m     11\u001b[39m model_inputs = tokenizer([text], return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m).to(device)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# generated_ids:Tensor其中包含输入数据，可以直接被用于reward_model打分，这一部分通过下面验证，\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# 可以发现用于训练reward_model的input_ids数据和generated_ids是一个结构的\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 因为它们decode后都是包含前置system、输入user、回答response三个部分\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m generated_ids = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\n\u001b[32m     18\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# generated_ids = [\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m#     output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# ]\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# 把回答全部输出出来，更美观\u001b[39;00m\n\u001b[32m     23\u001b[39m response = tokenizer.batch_decode(generated_ids, skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/align-anything/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/align-anything/lib/python3.11/site-packages/transformers/generation/utils.py:2465\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[39m\n\u001b[32m   2457\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2458\u001b[39m         input_ids=input_ids,\n\u001b[32m   2459\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2460\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2461\u001b[39m         **model_kwargs,\n\u001b[32m   2462\u001b[39m     )\n\u001b[32m   2464\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2465\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2466\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2470\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2472\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2473\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2476\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2477\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2478\u001b[39m         input_ids=input_ids,\n\u001b[32m   2479\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2480\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2481\u001b[39m         **model_kwargs,\n\u001b[32m   2482\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/align-anything/lib/python3.11/site-packages/transformers/generation/utils.py:3490\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3487\u001b[39m     streamer.put(next_tokens.cpu())\n\u001b[32m   3489\u001b[39m unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)\n\u001b[32m-> \u001b[39m\u001b[32m3490\u001b[39m this_peer_finished = \u001b[43munfinished_sequences\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m == \u001b[32m0\u001b[39m\n\u001b[32m   3491\u001b[39m cur_len += \u001b[32m1\u001b[39m\n\u001b[32m   3493\u001b[39m \u001b[38;5;66;03m# This is needed to properly delete outputs.logits which may be very large for first iteration\u001b[39;00m\n\u001b[32m   3494\u001b[39m \u001b[38;5;66;03m# Otherwise a reference to outputs is kept which keeps the logits alive in the next iteration\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "res=get_batch_rewards_from_two_model(model_raw,tokenizer_raw,model_dpo,tokenizer_dpo,data,model_reward,'mam.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12e98a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "align-anything",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
